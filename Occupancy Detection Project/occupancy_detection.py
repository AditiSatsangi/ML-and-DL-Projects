# -*- coding: utf-8 -*-
"""Occupancy detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HIX4_PyDrm8OPiVDpHcNMNEp0GVFHKyu
"""



import cv2
import numpy as np

# Load pre-trained human detection model
hog = cv2.HOGDescriptor()
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

# Function to predict occupancy
def predict_occupancy(image_path):
    # Load image
    image = cv2.imread(image_path)

    # Resize image if needed
    # image = cv2.resize(image, (width, height))

    # Detect humans in the image
    boxes, _ = hog.detectMultiScale(image, winStride=(8, 8), padding=(4, 4), scale=1.05)

    # If humans are detected, consider the room as occupied
    if len(boxes) > 0:
        return 1
    else:
        return 0

# Test the occupancy prediction function with an image
image_path = 'im.jpg'
prediction = predict_occupancy(image_path)
print("Predicted Occupancy:", prediction)

pip install serial

from google.colab.patches import cv2_imshow
import cv2

# Load pre-trained human detection model
hog = cv2.HOGDescriptor()
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

# Open a video capture object
video_path = 'k.mp4'
cap = cv2.VideoCapture(video_path)

while cap.isOpened():
    ret, frame = cap.read()

    if not ret:
        break

    # Detect humans in the frame
    boxes, _ = hog.detectMultiScale(frame, winStride=(8, 8), padding=(4, 4), scale=1.05)

    # Draw bounding boxes around detected humans
    for (x, y, w, h) in boxes:
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Display the frame with detections using cv2_imshow
    cv2_imshow(frame)

    # Display the number of detected people
    num_people = len(boxes)
    print("Number of People:", num_people)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

from google.colab.patches import cv2_imshow
import cv2

# Load pre-trained human detection model
hog = cv2.HOGDescriptor()
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

# Open a video capture object
video_path = 'k.mp4'
cap = cv2.VideoCapture(video_path)

# Manually set the frame rate (approximate value)
frame_rate = 1

while cap.isOpened():
    ret, frame = cap.read()

    if not ret:
        break

    # Detect humans in the frame
    boxes, _ = hog.detectMultiScale(frame, winStride=(8, 8), padding=(4, 4), scale=1.05)

    # Draw bounding boxes around detected humans
    for (x, y, w, h) in boxes:
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Display the frame with detections using cv2_imshow
    cv2_imshow(frame)

    # Display the number of detected people
    num_people = len(boxes)
    print("Number of People:", num_people)

    if cv2.waitKey(1000 // frame_rate) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

from google.colab.patches import cv2_imshow
import cv2

# Load pre-trained human detection model
hog = cv2.HOGDescriptor()
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

# Open a video capture object
video_path = 'k.mp4'
cap = cv2.VideoCapture(video_path)

# Manually set the frame rate (approximate value)
frame_rate = 1

while cap.isOpened():
    ret, frame = cap.read()

    if not ret:
        break

    # Detect humans in the frame
    boxes, _ = hog.detectMultiScale(frame, winStride=(8, 8), padding=(4, 4), scale=1.05)

    # Draw bounding boxes around detected humans
    for (x, y, w, h) in boxes:
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Display the frame with detections using cv2_imshow
    cv2_imshow(frame)

    # Display the number of detected people
    num_people = len(boxes)
    print("Number of People:", num_people)

    # Calculate delay based on frame rate
    delay = int(1000 / frame_rate)  # Convert frame rate to milliseconds
    if cv2.waitKey(delay) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()